{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wave 19 (post election) panel data\n",
    "df_18 = pd.read_spss('./data/wave18.sav')\n",
    "df_19 = pd.read_spss('./data/wave19.sav')\n",
    "df_backup18 = df_18.copy()\n",
    "df_backup19 = df_19.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset df\n",
    "df_18 = df_backup18.copy()\n",
    "df_19 = df_backup19.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in df_18.columns:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target variable cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows of participants who did not vote for one of the major parties\n",
    "df_19.drop(df_19[df_19['generalElectionVote'] == 'An independent candidate'].index, axis=0, inplace = True)\n",
    "df_19.drop(df_19[df_19['generalElectionVote'] == 'Other'].index, axis=0, inplace = True)\n",
    "df_19.drop(df_19[df_19['generalElectionVote'] == \"Don't know\"].index, axis=0, inplace = True)\n",
    "df_19['generalElectionVote'] = df_19['generalElectionVote'].cat.remove_unused_categories()\n",
    "\n",
    "df_18.drop(df_18[df_18['generalElectionVote'] == 'An independent candidate'].index, axis=0, inplace = True)\n",
    "df_18.drop(df_18[df_18['generalElectionVote'] == 'Other'].index, axis=0, inplace = True)\n",
    "df_18.drop(df_18[df_18['generalElectionVote'] == \"Don't know\"].index, axis=0, inplace = True)\n",
    "df_18['generalElectionVote'] = df_18['generalElectionVote'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows of participants who did not know if they voted\n",
    "#replace nans with DNV label\n",
    "df_18['generalElectionVote'].replace({'I would/did not vote': 'DNV'}, inplace=True)\n",
    "#     df['generalElectionVote'] = df['generalElectionVote'].cat.add_categories(\"DNV\")\n",
    "df_18['generalElectionVote'].fillna('DNV', inplace=True)\n",
    "df_18.rename(columns={'generalElectionVote': 'predictVote'}, inplace=True)\n",
    "    \n",
    "df_19.drop(df_19[df_19['p_turnout_2019'] == \"Don't know\"].index, axis=0, inplace = True)\n",
    "df_19.drop(df_19[df_19['p_turnout_2019'] == \"nan\"].index, axis=0, inplace = True)\n",
    "df_19['p_turnout_2019'] = df_19['p_turnout_2019'].cat.remove_unused_categories()\n",
    "#replace nans with DNV label\n",
    "df_19['generalElectionVote'] = df_19['generalElectionVote'].cat.add_categories(\"DNV\")\n",
    "df_19['generalElectionVote'].fillna('DNV', inplace=True)\n",
    "df_19.rename(columns={'generalElectionVote': 'actualVote'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe with merged columns\n",
    "df_19 = df_19.filter(['id', 'actualVote'])\n",
    "df = pd.merge(df_18, df_19, on='id')\n",
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset df (make sure to comment out when running model)\n",
    "# df = df_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are not relevant to prediction of generalElectionVote \n",
    "# drop questions that are too brexit specific (can't extrapolate)\n",
    "# drop country specific questions\n",
    "#drop wave19 specific questions\n",
    "columns_to_drop = ['id', 'starttime', 'endtime', 'wt', 'mii', 'likeBerry', 'brexitNextPref', 'cantLiveWithEU_1', 'cantLiveWithEU_2', 'cantLiveWithEU_3',\n",
    "                   'cantLiveWithEU_4', 'cantLiveWithEU_None', 'scotReferendumIntention', 'partyContact1', 'partyContactCon', 'partyContactLab',\n",
    "                   'partyContactLD', 'partyContactSNP', 'partyContactPC', 'partyContactBrexit', 'partyContactGrn', 'partyContactUKIP',\n",
    "                   'partyContact2new_13', 'partyContactOtherParty', 'partyContactNone', 'partyContactCon_1', 'partyContactCon_2', 'partyContactCon_3',\n",
    "                   'partyContactCon_4', 'partyContactCon_5', 'partyContactCon_6', 'partyContactCon_7', 'partyContactLab_1', 'partyContactLab_2',\n",
    "                   'partyContactLab_3', 'partyContactLab_4', 'partyContactLab_5', 'partyContactLab_6', 'partyContactLab_7', 'partyContactLD_1',\n",
    "                   'partyContactLD_2', 'partyContactLD_3', 'partyContactLD_4', 'partyContactLD_5', 'partyContactLD_6', 'partyContactLD_7',\n",
    "                   'partyContactSNP_1', 'partyContactSNP_2', 'partyContactSNP_3', 'partyContactSNP_4', 'partyContactSNP_5', 'partyContactSNP_6',\n",
    "                   'partyContactSNP_7', 'partyContactPC_1', 'partyContactPC_2', 'partyContactPC_3', 'partyContactPC_4', 'partyContactPC_5',\n",
    "                   'partyContactPC_6', 'partyContactPC_7', 'partyContactUKIP_1', 'partyContactUKIP_2', 'partyContactUKIP_3', 'partyContactUKIP_4', \n",
    "                   'partyContactUKIP_5', 'partyContactUKIP_6', 'partyContactUKIP_7', 'partyContactGreen_1', 'partyContactGreen_2', 'partyContactGreen_3',\n",
    "                   'partyContactGreen_4', 'partyContactGreen_5', 'partyContactGreen_6', 'partyContactGreen_7', 'partyContactBrexit_1',\n",
    "                   'partyContactBrexit_2', 'partyContactBrexit_3', 'partyContactBrexit_4', 'partyContactBrexit_5', 'partyContactBrexit_6',\n",
    "                   'partyContactBrexit_7', 'partyContactInd_1', 'partyContactInd_2', 'partyContactInd_3', 'partyContactInd_4', 'partyContactInd_5',\n",
    "                   'partyContactInd_6', 'partyContactInd_7', 'partyContactOther_1', 'partyContactOther_2', 'partyContactOther_3', 'partyContactOther_4',\n",
    "                   'partyContactOther_5', 'partyContactOther_6', 'partyContactOther_7', 'changeView', 'selfOccStatus', 'selfOccSupervise',\n",
    "                   'selfOccOrgSize', 'selfOccEmployees', 'selfNumEmployees', 'selfOccStatusLast', 'selfOccSuperviseLast', 'selfOccOrgSizeLast',\n",
    "                   'selfOccEmployeesLast', 'selfNumEmployeesLast', 'occCheck', 'respdate', 'oslaua', 'parentNumEmployees', 'headHouseholdPast', 'pano',\n",
    "                   'ageGroup', 'pcon', 'p_education_age', 'p_education', 'p_gross_personal', 'p_marital', 'p_paper_read', 'p_religion', 'p_work_stat',\n",
    "                   'p_scot_const_vote_2011', 'p_scot_list_vote_2011', 'p_scot_const_vote_2016', 'p_scot_list_vote_2016', 'p_welsh_const_vote_2016',\n",
    "                   'p_welsh_list_vote_2016', 'p_turnout_scot_ref', 'p_edlevelUni', 'wt_daily', 'turnoutUKGeneral','generalElectionVotePost',\n",
    "                   'generalElectionVoteUnsqueeze', 'generalElectionVoteSqueeze', 'generalElectionVoteRetro2017', 'generalElectionCertaintyUnsq', \n",
    "                   'generalElectionCertaintySq', 'ns_secW16W17', 'ns_sec_analyticW16W17', 'postalTurnout', 'noChanceCoalitionLab', 'noChanceCoalitionCon',\n",
    "                   'noChanceCoalitionLD', 'noChanceCoalitionSNP', 'noChanceCoalitionPC', 'noChanceCoalitionBrexit', 'noChanceCoalitionGrn',\n",
    "                   'noChanceCoalitionDUP', 'noChanceCoalitionNone', 'labPartnerLD', 'labPartnerSNP', 'labPartnerPC', 'labPartnerGreen',\n",
    "                   'labPartnerBrexit', 'conPartnerLD', 'conPartnerSNP', 'conPartnerPC', 'conPartnerGreen', 'conPartnerBrexit', 'conCampaignGoing',\n",
    "                   'labCampaignGoing', 'ldCampaignGoing', 'brexCampaignGoing', 'winConstituencyInd', 'constituencyWinReason1', 'constituencyWinReason2',\n",
    "                   'constituencyWinReason3', 'constituencyWinReason4', 'constituencyWinReason5', 'constituencyWinReason6', 'constituencyWinReason7',\n",
    "                   'constituencyWinReason8', 'constituencyWinReason9', 'constituencyWinReason10', 'constituencyWinReason11', 'constituencyWinReason12',\n",
    "                   'constituencyWinReason13', 'constituencyWinReason111', 'conUnited', 'labUnited', 'ldUnited', 'snpUnited', 'pcUnited', 'brexitUnited',\n",
    "                   'grnUnited','EUIntegrationJohnson', 'EUIntegrationCorbyn', 'dealVremain', 'conBrexPref', 'labBrexPref', 'ldBrexPref',\n",
    "                   'snpBrexPref', 'pcBrexPref', 'greenBrexPref', 'brexitBrexPref', 'mpBrexitView', 'handleEUNegotiate', 'achieveReduceImmigLD',\n",
    "                   'achieveReduceImmigSNP', 'achieveReduceImmigPC', 'achieveReduceImmigGrn', 'achieveReduceImmigBrexit', 'achieveReduceImmigNone', \n",
    "                   'ptvCon', 'ptvLab', 'ptvLD', 'ptvSNP', 'ptvPC', 'ptvUKIP', 'ptvBrexitParty', 'ptvGrn', 'changeEconomy', 'changeNHS', 'changeEducation',\n",
    "                   'changeEconomyLab', 'changeNHSLab', 'changeEducationLab', 'cutsTooFarNational', 'cutsTooFarNHS', 'cutsTooFarLocal', 'privatTooFar', \n",
    "                   'enviroProtection', 'scotCon', 'scotLab', 'scotLD', 'scotSNP', 'scotGrn', 'scotBrexit', 'welshCon', 'welshLab', 'welshLD', 'welshPC',\n",
    "                   'welshGrn', 'welshBrexit', 'polPreferToFight', 'conTone', 'labTone', 'ldTone', 'snpTone', 'pcTone', 'brexitTone', 'grnTone',\n",
    "                   'discussPolDays', 'agreeParty', 'tryConvince_1', 'tryConvince_2', 'tryConvince_3', 'tryConvince_4', 'tryConvince_5',\n",
    "                   'convinceFriends_1', 'convinceFriends_2', 'convinceFriends_3', 'convinceFriends_4', 'convinceFriends_5', 'convinceFriends_12',\n",
    "                   'convinceFriends_7', 'convinceFriends_6', 'convinceFriends_13', 'convinceFriends_9', 'convinceFamily_1', 'convinceFamily_2',\n",
    "                   'convinceFamily_3', 'convinceFamily_4', 'convinceFamily_5', 'convinceFamily_12', 'convinceFamily_7', 'convinceFamily_6',\n",
    "                   'convinceFamily_13', 'convinceFamily_9', 'convinceWork_1', 'convinceWork_2', 'convinceWork_3', 'convinceWork_4', 'convinceWork_5',\n",
    "                   'convinceWork_12', 'convinceWork_7', 'convinceWork_6', 'convinceWork_13', 'convinceWork_9', 'convinceOther_1', 'convinceOther_2',\n",
    "                   'convinceOther_3', 'convinceOther_4', 'convinceOther_5', 'convinceOther_12', 'convinceOther_7', 'convinceOther_6', 'convinceOther_13',\n",
    "                   'convinceOther_9', 'methodFriends_1', 'methodFriends_2', 'methodFriends_3', 'methodFriends_4', 'methodFriends_5', 'methodFriends_6',\n",
    "                   'methodFriends_111', 'methodFamily_1', 'methodFamily_2', 'methodFamily_3', 'methodFamily_4', 'methodFamily_5', 'methodFamily_6',\n",
    "                   'methodFamily_111', 'methodWork_1', 'methodWork_2', 'methodWork_3', 'methodWork_4', 'methodWork_5', 'methodWork_6', 'methodWork_111',\n",
    "                   'methodOther_1', 'methodOther_2', 'methodOther_3', 'methodOther_4', 'methodOther_5', 'methodOther_6', 'methodOther_111',\n",
    "                   'debateOneWatch', 'debateTwoWatch', 'debateClimateWatch', 'debateFourWatch', 'debateFiveWatch', 'debateSixWatch', 'xtoday_date',\n",
    "                   'xyesterday_date', 'xbefore_yesterday_date', 'xbefore_yesterday_day', 'S1_1', 'S1_2', 'S1_3', 'S1_4', 'S1_5', 'S1_6', 'S1_7', 'S1_8',\n",
    "                   'S1_9', 'paperLastThreeDays', 'paperLast3_1', 'paperLast3_2', 'paperLast3_3', 'paperLast3_4', 'paperLast3_5', 'paperLast3_6',\n",
    "                   'paperLast3_7', 'paperLast3_8', 'paperLast3_9', 'paperLast3_10', 'paperLast3_11', 'paperLast3_12', 'paperLast3_13', 'paperLast3_14',\n",
    "                   'paperLast3_15', 'paperLast3_16', 'paperLast3_17', 'paperLast3_18', 'paperLast3_19', 'paperLast3_20', 'papersLastThree_multiple_99',\n",
    "                   'paperDays_1_1', 'paperDays_1_2', 'paperDays_1_3', 'paperDays_1_111', 'paperDays_2_1', 'paperDays_2_2', 'paperDays_2_3',\n",
    "                   'paperDays_2_111', 'paperDays_3_1', 'paperDays_3_2', 'paperDays_3_3', 'paperDays_3_111', 'paperDays_4_1', 'paperDays_4_2',\n",
    "                   'paperDays_4_3', 'paperDays_4_111', 'paperDays_5_1', 'paperDays_5_2', 'paperDays_5_3', 'paperDays_5_111', 'paperDays_6_1',\n",
    "                   'paperDays_6_2', 'paperDays_6_3', 'paperDays_6_111', 'paperDays_7_1', 'paperDays_7_2', 'paperDays_7_3', 'paperDays_7_111',\n",
    "                   'paperDays_8_1', 'paperDays_8_2', 'paperDays_8_3', 'paperDays_8_111', 'paperDays_9_1', 'paperDays_9_2', 'paperDays_9_3',\n",
    "                   'paperDays_9_111', 'paperDays_10_1', 'paperDays_10_2', 'paperDays_10_3', 'paperDays_10_111', 'paperDays_11_1', 'paperDays_11_2',\n",
    "                   'paperDays_11_3', 'paperDays_11_111', 'paperDays_12_1', 'paperDays_12_2', 'paperDays_12_3', 'paperDays_12_111', 'paperDays_13_1',\n",
    "                   'paperDays_13_2', 'paperDays_13_3', 'paperDays_13_111', 'paperDays_14_1', 'paperDays_14_2', 'paperDays_14_3', 'paperDays_14_111',\n",
    "                   'paperDays_15_1', 'paperDays_15_2', 'paperDays_15_3', 'paperDays_15_111', 'paperDays_16_1', 'paperDays_16_2', 'paperDays_16_3',\n",
    "                   'paperDays_16_111', 'paperDays_17_1', 'paperDays_17_2', 'paperDays_17_3', 'paperDays_17_111', 'paperDays_18_1', 'paperDays_18_2',\n",
    "                   'paperDays_18_3', 'paperDays_18_111', 'paperDays_19_1', 'paperDays_19_2', 'paperDays_19_3', 'paperDays_19_111', 'twitterUse', \n",
    "                   'twitterInfo_1', 'twitterInfo_2', 'twitterInfo_3', 'fbUse', 'fbInfo_1', 'fbInfo_2', 'fbInfo_3', 'sharedContentOnline_1', \n",
    "                   'sharedContentOnline_2', 'sharedContentOnline_3', 'sharedContentOnline_4', 'sharedContentOnline_5','dutyToVote2', 'socialPressureVote',\n",
    "                   'voteShareCon', 'voteShareLab', 'voteShareLD', 'voteShareBrexit', 'voteShareGreen', 'voteShareSNP', 'voteSharePC', 'voteShareOther',\n",
    "                   'voteShareConstCon', 'voteShareConstLab', 'voteShareConstLD', 'voteShareConstBrexit', 'voteShareConstGreen', 'voteShareConstSNP',\n",
    "                   'voteShareConstPC', 'voteShareConstOther','partyWin2017', 'partySecond2017', 'genElecTurnoutRetro2017', 'bringTogether', 'taxSpendSelf',\n",
    "                   'taxSpendCon', 'taxSpendLab', 'CampaignDay', 'cciW16W17', 'ccinoITW16W17', 'justITW16W17', 'jobzoneW16W17', 'workingStatusW16W17',\n",
    "                   'prevJobW16W17', 'p_past_vote_2019', 'p_turnout_2019', 'tacticalVoteWebsite', 'likeUKIP', 'infoNational', 'infoLocal', 'bestPM',\n",
    "                  'partyIdStrength']\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# rename leadership specific columns\n",
    "leader_columns = {'likeJohnson': 'likeConLeader', 'likeCorbyn': 'likeLabLeader', 'likeSwinson': 'likeLDLeader', 'likeSturgeon': 'likeSNPLeader',\n",
    "                 'likePrice': 'likePCLeader', 'likeFarage': 'likeBrexitPartyLeader', 'likeBartley': 'likeGrnLeader'}\n",
    "df.rename(columns=leader_columns, inplace=True)\n",
    "\n",
    "\n",
    "# encode nomial categories (using one hot encoding)\n",
    "columns_to_dummy = [ 'predictVote','partyId', 'partyIdSqueeze', 'bestOnMII', 'p_ethnicity', 'p_sexuality', 'p_socgrade', 'p_past_vote_2010', 'p_disability', \n",
    "                    'p_past_vote_2005', 'p_past_vote_2015', 'p_past_vote_2017', 'p_eurefvote', 'p_edlevel', 'country', 'gor', 'decidedVote']\n",
    "\n",
    "df = pd.get_dummies(df, columns=columns_to_dummy)\n",
    "\n",
    "\n",
    "#encode ordinal categories (using label encoding)\n",
    "# columns_to_le = ['partyIdStrength']\n",
    "# for i in columns_to_le:\n",
    "#     df[i] = df[i].cat.codes\n",
    "    \n",
    "# force categoies into boolean\n",
    "columns_to_boolean = ['participation_1', 'participation_2', 'participation_3', 'participation_4', 'participation_5', 'participation_6', 'euRefDoOver', \n",
    "                     'p_vote_scot_ref', 'p_eurefturnout', 'p_turnout_2015', 'p_turnout_2017', 'p_turnout_2010', 'p_turnout_2005', 'postalapply',\n",
    "                      'achieveReduceImmigCon', 'achieveReduceImmigLab']\n",
    "def category2(column):\n",
    "        if len(df[column].cat.categories) == 3:\n",
    "            df[column] = df[column].replace({df[column].cat.categories[0]: \"0\", df[column].cat.categories[1]: \"0\", df[column].cat.categories[2]: \"1\"})\n",
    "            df[column] = pd.to_numeric(df[column])\n",
    "        elif len(df[column].cat.categories) == 2:\n",
    "            df[column] = df[column].replace({df[column].cat.categories[0]: \"0\", df[column].cat.categories[1]: \"1\"})\n",
    "            df[column] = pd.to_numeric(df[column])\n",
    "        else:\n",
    "            print(column,': ERROR')\n",
    "for i in columns_to_boolean:\n",
    "    category2(i)\n",
    "    \n",
    "# encode 1-10 ordinal ratings into numerical values\n",
    "columns10 = ['likeCon', 'likeLab', 'likeLD', 'likeBrexitParty', 'likeSNP', 'likePC', 'likeGrn', 'likeConLeader', 'likeLabLeader',\n",
    "            'likeLDLeader', 'likeSNPLeader', 'likePCLeader', 'likeBrexitPartyLeader', 'likeGrnLeader', 'EUIntegrationSelf', 'EUIntegrationCon',\n",
    "            'EUIntegrationLab', 'EUIntegrationLD', 'EUIntegrationSNP', 'EUIntegrationPC', 'EUIntegrationGreen', 'EUIntegrationBrexit', 'leftRight',\n",
    "            'lrCon', 'lrLab','lrLD', 'lrSNP', 'lrPC', 'lrgreens', 'lrBrexit','redistSelf', 'redistCon', 'redistLab', 'redistLD', 'redistSNP', 'redistPC',\n",
    "             'redistBrexit', 'redistGreen']\n",
    "def category10(column):\n",
    "    df[column] = df[column].replace({df[column].cat.categories[10]: '0', df[column].cat.categories[11] : '10'})\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "for i in columns10:\n",
    "    category10(i)\n",
    "\n",
    "majorityP = ['majorityPartyCon', 'majorityPartyLab', 'majorityPartyLD', 'majorityPartyBrexit', 'hungParliamentResponse']\n",
    "def majority(column):\n",
    "    df[column] = df[column].replace({df[column].cat.categories[10]: '10', df[column].cat.categories[11] : '0'})\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "for i in majorityP:\n",
    "    majority(i)\n",
    "\n",
    "#encode 1-4 ordinal ratings into numerical values\n",
    "columns4 = ['electionInterest']\n",
    "def category4(column):\n",
    "    df[column] = df[column].replace({df[column].cat.categories[1]: \"1\", df[column].cat.categories[2]: \"2\", df[column].cat.categories[3]: \"3\", \n",
    "                                     df[column].cat.categories[4]: \"4\"})\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    \n",
    "for i in columns4:\n",
    "    category4(i)\n",
    "    \n",
    "#encode 1-7 ratings into numerical values\n",
    "columns7 = ['trustMPs', 'generalElectionCertainty']\n",
    "def category7(column):\n",
    "    df[column] = df[column].replace({df[column].cat.categories[5]: '7', df[column].cat.categories[7] : '1'})\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "for i in columns7:\n",
    "    category7(i)\n",
    "    \n",
    "#encode ratings on infosource columns\n",
    "info = ['infoSourceTV', 'infoSourcePaper', 'infoSourceRadio', 'infoSourceInternet']\n",
    "def infosource(column):\n",
    "    df[column] = df[column].replace({df[column].cat.categories[5]: '1', df[column].cat.categories[3]: '2', df[column].cat.categories[1]: '3',\n",
    "                                     df[column].cat.categories[0]: '4', df[column].cat.categories[4]: '5'})\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "for i in info:\n",
    "    infosource(i)\n",
    "\n",
    "#how likely is each party to win in your constituency\n",
    "likely_win = ['winConstituencyCon', 'winConstituencyLab', 'winConstituencyLD', 'winConstituencyBrexit', 'winConstituencyGreen', 'winConstituencyUKIP',\n",
    "              'winConstituencySNP', 'winConstituencyPC']\n",
    "def winConstituency(column):\n",
    "    df[column] = df[column].replace({'0 - Very unlikely to win': '0', '100 - Very likely to win': '100'})\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "for i in likely_win:\n",
    "    winConstituency(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset df (comment out when running model)\n",
    "# df = df_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding gender\n",
    "df['gender'].replace({\"Female\": \"0\", \"Male\": \"1\"}, inplace=True)\n",
    "df['gender'] = pd.to_numeric(df['gender'])\n",
    "df['gender'].fillna(1, inplace=True)\n",
    "# encoding euRefVote\n",
    "df['euRefVote'].replace({\"Stay/remain in the EU\": 'Remain', \"I would/will not vote\": \"DNV\", \"Don't know\": \"DNV\", \"Leave the EU\": \"Leave\"}, inplace=True)\n",
    "df = pd.get_dummies(df, columns=['euRefVote'])\n",
    "#set age to numeric\n",
    "df['age'] = pd.to_numeric(df['age'])\n",
    "# household income\n",
    "df['p_gross_household'] = df['p_gross_household'].replace({'under £5,000 per year': '0', '£10,000 to £14,999 per year': '10000', '£100,000 to £149,999 per year': '100000',\n",
    "                                                         '£15,000 to £19,999 per year': '15000', '£150,000 and over': '150000', '£20,000 to £24,999 per year': '20000',\n",
    "                                                         '£25,000 to £29,999 per year': '25000', '£30,000 to £34,999 per year': '30000',\n",
    "                                                         '£35,000 to £39,999 per year': '35000', '£40,000 to £44,999 per year': '40000', '£45,000 to £49,999 per year': '45000',\n",
    "                                                         '£5,000 to £9,999 per year': '5000', '£50,000 to £59,999 per year': '50000', '£60,000 to £69,999 per year': '60000',\n",
    "                                                         '£70,000 to £99,999 per year': '70000'})\n",
    "df['p_gross_household'] = pd.to_numeric(df['p_gross_household'], errors='coerce')\n",
    "# number of people living in household\n",
    "df['p_hh_size'].replace({'8 or more': 8}, inplace=True)\n",
    "df['p_hh_size'] = pd.to_numeric((df['p_hh_size']), errors='coerce')\n",
    "# homeowner or rent\n",
    "df['p_housing'].replace({'Neither – I live rent-free with my parents, family or friends': 'Neither', 'Neither – I live with my parents, family or friends but pay some rent to them': 'Neither',\n",
    "                        'Other': 'Neither', 'Own (part-own) – through shared ownership scheme (i.e. pay part mortgage, part rent)': 'Own',\n",
    "                        'Own – outright': 'Own', 'Own – with a mortgage': 'Own', 'Rent – from a housing association': 'Rent',\n",
    "                        'Rent – from a private landlord': 'Rent', 'Rent – from my local authority': 'Rent'}, inplace=True)\n",
    "df = pd.get_dummies(df, columns=['p_housing'])\n",
    "#parent\n",
    "df['p_parent'] = pd.to_numeric((df['p_parent']), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23218, 164)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove any columms cotaining NaN values\n",
    "df.dropna(axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #split dataset in features and target variable\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove('actualVote')\n",
    "\n",
    "X = df[feature_cols] # Features\n",
    "y = df.actualVote # Target variable\n",
    "\n",
    "#feature selection\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest, chi2\n",
    "\n",
    "X = SelectKBest(chi2, k=20).fit_transform(X, y)\n",
    "\n",
    "# # Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bnb.predict(X_test)\n",
    "predictions = [value for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : Accuracy: 81.57%\n",
      "20 : Accuracy: 85.29%\n",
      "30 : Accuracy: 84.54%\n",
      "40 : Accuracy: 83.20%\n",
      "50 : Accuracy: 82.77%\n",
      "60 : Accuracy: 82.47%\n",
      "70 : Accuracy: 82.40%\n",
      "80 : Accuracy: 82.23%\n",
      "90 : Accuracy: 82.14%\n",
      "100 : Accuracy: 82.29%\n",
      "110 : Accuracy: 82.34%\n",
      "120 : Accuracy: 82.13%\n",
      "130 : Accuracy: 82.13%\n",
      "140 : Accuracy: 82.10%\n",
      "150 : Accuracy: 82.08%\n",
      "160 : Accuracy: 82.07%\n"
     ]
    }
   ],
   "source": [
    "# testing number of features\n",
    "num_feat = range(10, 170, 10)\n",
    "for i in num_feat:\n",
    "    feature_cols = list(df.columns)\n",
    "    feature_cols.remove('actualVote')\n",
    "    X = df[feature_cols] # Features\n",
    "    y = df.actualVote # Target variable\n",
    "    X = SelectKBest(chi2, k=i).fit_transform(X, y)\n",
    "    # # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "    #Create a Classifier\n",
    "    bnb = BernoulliNB()\n",
    "    #Train the model using the training sets\n",
    "    bnb.fit(X_train, y_train)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = bnb.predict(X_test)\n",
    "    predictions = [value for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(i,\": Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
